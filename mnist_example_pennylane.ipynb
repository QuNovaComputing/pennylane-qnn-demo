{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell imports all required libraries. We use pytorch to define and train neural networks as well as provide the classical layers. We use torchvision to load the MNIST digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch dataset loading, model definition, and model training code\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# pennylane imports for defining the quantum part of the model\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as np\n",
    "\n",
    "\n",
    "# for timing the training process\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we handle loading the MNIST digits and optionally select a reduced set of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: /home/rpj/pytorch_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "\n",
      "Test data:\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: /home/rpj/pytorch_data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "# load the MNIST training and testing datasets\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"~/pytorch_data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"~/pytorch_data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# allow for restricting classes to specific digits\n",
    "from functools import reduce\n",
    "def restrict_classes(dataset, classes):\n",
    "    classes_membership_mask = reduce(lambda a,b: a|b,\n",
    "                                     [dataset.targets == i for i in classes],\n",
    "                                     torch.zeros(dataset.targets.size(), dtype=int))\n",
    "    idx = torch.where(classes_membership_mask)\n",
    "    dataset.data = dataset.data[idx]\n",
    "    dataset.targets = dataset.targets[idx]\n",
    "    return dataset\n",
    "\n",
    "# NOTE: you can change this list to select which digit classes are\n",
    "# used from the datasets.\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "print(\"Train data:\")\n",
    "print(restrict_classes(training_data, classes))\n",
    "print()\n",
    "print(\"Test data:\")\n",
    "print(restrict_classes(test_data, classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines the hybrid model. We first define the quantum part, then the hybrid model class that makes use of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rpj/workspace/qunova_VQE/venv/lib/python3.8/site-packages/pennylane_lightning/lightning_qubit/lightning_qubit.py:824: UserWarning: Pre-compiled binaries for lightning.qubit are not available. Falling back to using the Python-based default.qubit implementation. To manually compile from source, follow the instructions at https://pennylane-lightning.readthedocs.io/en/latest/installation.html.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# NOTE: here, we configure the hyperparameters of the quantum layer.\n",
    "# You must install the lightning.qubit device for cpu runs or\n",
    "# lightning.gpu device for gpu runs. You can also set use_lightning=False\n",
    "# to use the slow default.qubit backend.\n",
    "nqubits = 4\n",
    "nlayers = 2\n",
    "use_lightning = False\n",
    "use_gpu = False\n",
    "\n",
    "# default to cpu pytorch ops\n",
    "torch_device = \"cpu\"\n",
    "if use_lightning:\n",
    "    if use_gpu:\n",
    "        qml_device = qml.device('lightning.gpu', wires=nqubits)\n",
    "        # override to use gpu in pytorch\n",
    "        torch_device = \"cuda\"\n",
    "    else:\n",
    "        qml_device = qml.device('lightning.qubit', wires=nqubits)\n",
    "else:\n",
    "    if use_gpu:\n",
    "        raise RuntimeError(\"Cannot use gpu without also using lightning simulator.\")\n",
    "    qml_device = qml.device('qulacs.simulator', wires=nqubits)\n",
    "\n",
    "# Here we define the quantum part of the model\n",
    "@qml.qnode(qml_device, interface=\"torch\")\n",
    "def qnn_layer(inputs, weights):\n",
    "    # encode inputs from previous layer\n",
    "    # as rotations.\n",
    "    for i in range(nqubits):\n",
    "        qml.RX(inputs[i], wires=i)\n",
    "    # place gates using the trainable weights\n",
    "    # as parameters.\n",
    "    for layer_index in range(nlayers):\n",
    "        # place the trainable rotations\n",
    "        for i in range(nqubits):\n",
    "            qml.RY(weights[i + layer_index * nqubits], wires=i)\n",
    "        # place the entangling gates\n",
    "        for i in range(nqubits):\n",
    "            j = (i + 1) % nqubits\n",
    "            qml.CNOT(wires=(i, j))\n",
    "    # now, return the pauli Z expectation values\n",
    "    # on each qubit.\n",
    "    return tuple(qml.expval(qml.PauliZ(i)) for i in range(nqubits))\n",
    "\n",
    "\n",
    "class HybridClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # to convert image arrays to vectors\n",
    "        self.flatten = nn.Flatten()\n",
    "        # to reduce number of features for input to the qnn\n",
    "        self.reduction_layer = nn.Linear(28*28, nqubits)\n",
    "        # to map the qnn outputs to a class (some values are unused if\n",
    "        # not using all 10 classes)\n",
    "        self.output_layer = nn.Linear(nqubits, 10)\n",
    "\n",
    "        # This is the randomly initialised weights tensor for the quantum layer.\n",
    "        self.qnn_weights = torch.rand(nlayers * nqubits) * np.pi\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform image array to a vector\n",
    "        x = self.flatten(x)\n",
    "        # scale pixel values to [0, 1] range\n",
    "        x = x / 255.0\n",
    "        # apply classical dimensionality reduction layer\n",
    "        x = self.reduction_layer(x)\n",
    "        # apply pi*tanh activation to put data into the range from -pi\n",
    "        # to pi\n",
    "        x = torch.tanh(x) * torch.pi\n",
    "        # apply the qnn layer to the input and weights.\n",
    "        # older versions of pennylane do not support batches,\n",
    "        # so we iterate through the batch and apply the qnn manually.\n",
    "        batch_size = x.size(0)\n",
    "        out = torch.empty((batch_size, nqubits), dtype=torch.float)\n",
    "        for batch_index in range(batch_size):\n",
    "            expval_tensors = qnn_layer(x[batch_index], self.qnn_weights)\n",
    "            expval_floats = [t.item() for t in expval_tensors]\n",
    "            out[batch_index] = torch.tensor(expval_floats)\n",
    "        x = out\n",
    "        # apply output layer to combine qnn outputs to 10 numbers\n",
    "        x = self.output_layer(x)\n",
    "        # just return outputs since we will use cross entropy loss in\n",
    "        # training\n",
    "        return x\n",
    "\n",
    "model = HybridClassifier().to(torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell defines function to run single epochs / passes of training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the below code is all used to train the defined model\n",
    "# and will be run when this file is loaded.\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(torch_device)\n",
    "        y = y.to(torch_device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    pred = None\n",
    "    X = None\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(torch_device)\n",
    "            y = y.to(torch_device)\n",
    "            pred = model(X)\n",
    "            predicted_label = torch.argmax(pred, dim=1)\n",
    "            correct += torch.count_nonzero(predicted_label == y)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    print(f\"Accuracy: {correct / (len(dataloader) * batch_size) * 100}\")\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell will start the training process when executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training\n",
      "--------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb Cell 10\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBefore training\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m--------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m test_loop(test_dataloader, model, loss_fn)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m--------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(torch_device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(torch_device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m predicted_label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(pred, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcount_nonzero(predicted_label \u001b[39m==\u001b[39m y)\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb Cell 10\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mempty((batch_size, nqubits), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch_index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(batch_size):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m     expval_tensors \u001b[39m=\u001b[39m qnn_layer(x[batch_index], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnn_weights)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     expval_floats \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mitem() \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m expval_tensors]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rpj/workspace/qunova_VQE/scratch/dev/qml/pytorch/pennylane_example/mnist_example_pennylane.ipynb#W4sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     out[batch_index] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(expval_floats)\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/pennylane/qnode.py:1027\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         full_transform_program\u001b[39m.\u001b[39m_set_all_argnums(\n\u001b[1;32m   1023\u001b[0m             \u001b[39mself\u001b[39m, args, kwargs, argnums\n\u001b[1;32m   1024\u001b[0m         )  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m-> 1027\u001b[0m res \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1028\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,),\n\u001b[1;32m   1029\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m   1030\u001b[0m     gradient_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_fn,\n\u001b[1;32m   1031\u001b[0m     interface\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface,\n\u001b[1;32m   1032\u001b[0m     transform_program\u001b[39m=\u001b[39;49mfull_transform_program,\n\u001b[1;32m   1033\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m   1034\u001b[0m     gradient_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_kwargs,\n\u001b[1;32m   1035\u001b[0m     override_shots\u001b[39m=\u001b[39;49moverride_shots,\n\u001b[1;32m   1036\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_kwargs,\n\u001b[1;32m   1037\u001b[0m )\n\u001b[1;32m   1039\u001b[0m res \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1041\u001b[0m \u001b[39m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/pennylane/interfaces/execution.py:616\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[39m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[1;32m    615\u001b[0m \u001b[39mif\u001b[39;00m no_interface_boundary_required:\n\u001b[0;32m--> 616\u001b[0m     results \u001b[39m=\u001b[39m inner_execute(tapes)\n\u001b[1;32m    617\u001b[0m     \u001b[39mreturn\u001b[39;00m post_processing(results)\n\u001b[1;32m    619\u001b[0m _grad_on_execution \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/pennylane/interfaces/execution.py:249\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes, **_)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39mif\u001b[39;00m numpy_only:\n\u001b[1;32m    248\u001b[0m     tapes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(qml\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tapes)\n\u001b[0;32m--> 249\u001b[0m \u001b[39mreturn\u001b[39;00m cached_device_execution(tapes)\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/pennylane/interfaces/execution.py:371\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[39mreturn\u001b[39;00m (res, []) \u001b[39mif\u001b[39;00m return_tuple \u001b[39melse\u001b[39;00m res\n\u001b[1;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[39m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[1;32m    370\u001b[0m     \u001b[39m# convert to list as new device interface returns a tuple\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(fn(\u001b[39mtuple\u001b[39;49m(execution_tapes\u001b[39m.\u001b[39;49mvalues()), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    373\u001b[0m final_res \u001b[39m=\u001b[39m []\n\u001b[1;32m    375\u001b[0m \u001b[39mfor\u001b[39;00m i, tape \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tapes):\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/python-3.8/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/pennylane/_qubit_device.py:458\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[0;34m(self, circuits)\u001b[0m\n\u001b[1;32m    454\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m    455\u001b[0m \u001b[39mfor\u001b[39;00m circuit \u001b[39min\u001b[39;00m circuits:\n\u001b[1;32m    456\u001b[0m     \u001b[39m# we need to reset the device here, else it will\u001b[39;00m\n\u001b[1;32m    457\u001b[0m     \u001b[39m# not start the next computation in the zero state\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset()\n\u001b[1;32m    460\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute(circuit)\n\u001b[1;32m    461\u001b[0m     results\u001b[39m.\u001b[39mappend(res)\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/pennylane/devices/default_qubit_legacy.py:942\u001b[0m, in \u001b[0;36mDefaultQubitLegacy.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    941\u001b[0m \u001b[39m# init the state vector to |00..0>\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_basis_state(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    943\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_rotated_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\n",
      "File \u001b[0;32m~/workspace/qunova_VQE/venv/lib/python3.8/site-packages/pennylane/devices/default_qubit_legacy.py:716\u001b[0m, in \u001b[0;36mDefaultQubitLegacy._create_basis_state\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    714\u001b[0m state \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_wires, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mcomplex128)\n\u001b[1;32m    715\u001b[0m state[index] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 716\u001b[0m state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_asarray(state, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_DTYPE)\n\u001b[1;32m    717\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reshape(state, [\u001b[39m2\u001b[39m] \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_wires)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Before training\\n--------------------------\")\n",
    "test_loop(test_dataloader, model, loss_fn)\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n--------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Training took {elapsed_time/60:.2f} minutes.\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
